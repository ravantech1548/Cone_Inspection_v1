# SSL Certificate Fix - Self-Signed Certificates

## Problem

Frontend showing: **"‚ö†Ô∏è No model classes found"**

**Root Cause**: Node.js `fetch()` rejects self-signed SSL certificates by default when making HTTPS requests to the inference service.

---

## Solution Applied

Added HTTPS agent with `rejectUnauthorized: false` to allow self-signed certificates.

### Files Modified

#### 1. app/backend/src/routes/model.routes.js
```javascript
import https from 'https';

// Create HTTPS agent that allows self-signed certificates
const httpsAgent = new https.Agent({
  rejectUnauthorized: false
});

// Use agent in fetch
const fetchOptions = {
  method: 'GET',
  signal: AbortSignal.timeout(5000)
};

if (config.inference.serviceUrl.startsWith('https://')) {
  fetchOptions.agent = httpsAgent;
}

const response = await fetch(url, fetchOptions);
```

#### 2. app/backend/src/services/inference.service.js
```javascript
// Allow self-signed certificates for HTTPS
if (config.inference.serviceUrl.startsWith('https://')) {
  const https = await import('https');
  fetchOptions.agent = new https.Agent({
    rejectUnauthorized: false
  });
}
```

---

## What This Fixes

‚úÖ **Backend ‚Üí Inference Service** communication over HTTPS  
‚úÖ **Model classes** now load correctly  
‚úÖ **YOLO classification** works with HTTPS  
‚úÖ **Self-signed certificates** accepted  

---

## Restart Backend

After this fix, restart the backend:

```bash
# Stop backend (Ctrl+C)
cd app/backend
npm start
```

---

## Verify Fix

### 1. Check Backend Logs
Should see successful connection to inference service:
```
[YOLO] Calling inference service: https://localhost:5000
[YOLO] Response status: 200
```

### 2. Check Frontend
- Login to application
- Create new batch
- Should see model classes in dropdown (e.g., "green_brown", "brown_purple_ring")

### 3. Test API
```bash
# Get model classes
curl -k -H "Authorization: Bearer YOUR_TOKEN" https://localhost:3001/api/model/classes
```

**Expected Response:**
```json
{
  "classes": ["green_brown", "brown_purple_ring", "brown_plain"],
  "num_classes": 3,
  "model_type": "YOLO"
}
```

---

## Why `rejectUnauthorized: false`?

### Development
- ‚úÖ Allows self-signed certificates
- ‚úÖ Simplifies local development
- ‚úÖ No need to trust certificates system-wide

### Production
For production, you should:
1. Use real SSL certificates (Let's Encrypt)
2. Remove `rejectUnauthorized: false`
3. Or use a reverse proxy (Nginx) to handle SSL

---

## Security Note

‚ö†Ô∏è **Development Only**

`rejectUnauthorized: false` disables SSL certificate validation. This is:
- ‚úÖ **Safe** for development on localhost
- ‚ùå **Not safe** for production

For production:
```javascript
// Production - validate certificates
const httpsAgent = new https.Agent({
  rejectUnauthorized: true  // Validate certificates
});
```

---

## Alternative Solutions

### Option 1: Trust Certificates System-Wide
```bash
# Windows
certutil -addstore -f "ROOT" certs\backend-cert.pem

# macOS
sudo security add-trusted-cert -d -r trustRoot -k /Library/Keychains/System.keychain certs/backend-cert.pem

# Linux
sudo cp certs/backend-cert.pem /usr/local/share/ca-certificates/
sudo update-ca-certificates
```

### Option 2: Use mkcert
```bash
# Install mkcert
brew install mkcert  # macOS
choco install mkcert  # Windows

# Create locally-trusted certificates
mkcert -install
mkcert localhost 127.0.0.1 ::1
```

### Option 3: Use HTTP for Development
```env
# .env
USE_HTTPS=false
INFERENCE_SERVICE_URL=http://localhost:5000
```

---

## Troubleshooting

### Still No Model Classes?

**Check:**
1. Inference service is running
2. Inference service is on HTTPS (if USE_HTTPS=true)
3. Backend can reach inference service
4. YOLO model is loaded

**Test Inference Service:**
```bash
curl -k https://localhost:5000/api/model-info
```

**Expected:**
```json
{
  "classes": ["green_brown", "brown_purple_ring", "brown_plain"],
  "num_classes": 3
}
```

### Certificate Error in Logs

**Error:** `unable to verify the first certificate`

**Solution:** Already fixed with `rejectUnauthorized: false`

### Connection Refused

**Error:** `ECONNREFUSED`

**Solution:** Start inference service:
```bash
cd inference-service
venv\Scripts\activate
python http_server.py
```

---

## Summary

‚úÖ **Self-signed certificates** now accepted  
‚úÖ **Backend ‚Üí Inference** communication works  
‚úÖ **Model classes** load correctly  
‚úÖ **Application** fully functional with HTTPS  

**Next Step:** Restart backend to apply changes! üîí
